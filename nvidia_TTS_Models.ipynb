{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tei2gn1Bhue8"
      },
      "outputs": [],
      "source": [
        "!pip install nemo_toolkit['all']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBhBY-0zvqhY"
      },
      "source": [
        "# TTS-EN-FASTPITCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccNYkKonmBnX",
        "outputId": "19df4720-a56b-4819-d501-c49201d90218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pynini\n",
            "  Downloading pynini-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29 in /usr/local/lib/python3.8/dist-packages (from pynini) (0.29.32)\n",
            "Installing collected packages: pynini\n",
            "Successfully installed pynini-2.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install pynini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiFfL_0dxbIj"
      },
      "source": [
        "tts_en_fastpitch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xDvCd9CiHyD",
        "outputId": "ec8a868e-99af-4583-e6a2-d189834d6e1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-01-06 11:19:07 tokenize_and_classify:87] Creating ClassifyFst grammars.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-01-06 11:19:57 experimental:27] Module <class 'nemo_text_processing.g2p.modules.IPAG2P'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2023-01-06 11:19:59 modules:95] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
            "[NeMo W 2023-01-06 11:19:59 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    dataset:\n",
            "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
            "      manifest_filepath: /ws/LJSpeech/nvidia_ljspeech_train_clean_ngc.json\n",
            "      sample_rate: 22050\n",
            "      sup_data_path: /raid/LJSpeech/supplementary\n",
            "      sup_data_types:\n",
            "      - align_prior_matrix\n",
            "      - pitch\n",
            "      n_fft: 1024\n",
            "      win_length: 1024\n",
            "      hop_length: 256\n",
            "      window: hann\n",
            "      n_mels: 80\n",
            "      lowfreq: 0\n",
            "      highfreq: 8000\n",
            "      max_duration: null\n",
            "      min_duration: 0.1\n",
            "      ignore_file: null\n",
            "      trim: false\n",
            "      pitch_fmin: 65.40639132514966\n",
            "      pitch_fmax: 2093.004522404789\n",
            "      pitch_norm: true\n",
            "      pitch_mean: 212.35873413085938\n",
            "      pitch_std: 68.52806091308594\n",
            "      use_beta_binomial_interpolator: true\n",
            "    dataloader_params:\n",
            "      drop_last: false\n",
            "      shuffle: true\n",
            "      batch_size: 24\n",
            "      num_workers: 0\n",
            "    \n",
            "[NeMo W 2023-01-06 11:19:59 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    dataset:\n",
            "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
            "      manifest_filepath: /ws/LJSpeech/nvidia_ljspeech_val_clean_ngc.json\n",
            "      sample_rate: 22050\n",
            "      sup_data_path: /raid/LJSpeech/supplementary\n",
            "      sup_data_types:\n",
            "      - align_prior_matrix\n",
            "      - pitch\n",
            "      n_fft: 1024\n",
            "      win_length: 1024\n",
            "      hop_length: 256\n",
            "      window: hann\n",
            "      n_mels: 80\n",
            "      lowfreq: 0\n",
            "      highfreq: 8000\n",
            "      max_duration: null\n",
            "      min_duration: null\n",
            "      ignore_file: null\n",
            "      trim: false\n",
            "      pitch_fmin: 65.40639132514966\n",
            "      pitch_fmax: 2093.004522404789\n",
            "      pitch_norm: true\n",
            "      pitch_mean: 212.35873413085938\n",
            "      pitch_std: 68.52806091308594\n",
            "      use_beta_binomial_interpolator: true\n",
            "    dataloader_params:\n",
            "      drop_last: false\n",
            "      shuffle: false\n",
            "      batch_size: 24\n",
            "      num_workers: 0\n",
            "    \n",
            "[NeMo W 2023-01-06 11:20:00 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:299: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
            "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-01-06 11:20:00 features:267] PADDING: 1\n",
            "[NeMo I 2023-01-06 11:20:01 save_restore_connector:243] Model FastPitchModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--tts_en_fastpitch/snapshots/2c8305b7b41b33fd6367f0635796dc3a7a33cbf9/tts_en_fastpitch.nemo.\n"
          ]
        }
      ],
      "source": [
        "# Load FastPitch\n",
        "from nemo.collections.tts.models import FastPitchModel\n",
        "spec_generator = FastPitchModel.from_pretrained(\"nvidia/tts_en_fastpitch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607,
          "referenced_widgets": [
            "d563b11073de4ddca69af5041317b5c5",
            "4786e17e28ef40e99e7bd1f689cc3db2",
            "8a0d1a5a30194ecb95ed105335aa7794",
            "1b06cc5610e14636b4278f61a7c323b1",
            "37973b413f5744308fdf2db22b9bc91a",
            "9bddd5b7a7d34d5cae8e01fc70ec3153",
            "1614edd509a74de7aa1e341630d11e67",
            "9a504b90dc96486bb99017cb1647a0cc",
            "c824928fdfae45d7a6cc901fd377f758",
            "d8c03d5f1c5b4dd28643c2113fd6b554",
            "e85fafcbca58451b92e9b44aa31b5947"
          ]
        },
        "id": "gtbKmJ3gziMs",
        "outputId": "0cae930b-6250-4c79-c6b5-d3b2ec89045a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d563b11073de4ddca69af5041317b5c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/315M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-01-06 11:20:19 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    dataset:\n",
            "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
            "      manifest_filepath: /home/fkreuk/data/train_finetune.txt\n",
            "      min_duration: 0.75\n",
            "      n_segments: 8192\n",
            "    dataloader_params:\n",
            "      drop_last: false\n",
            "      shuffle: true\n",
            "      batch_size: 64\n",
            "      num_workers: 4\n",
            "    \n",
            "[NeMo W 2023-01-06 11:20:19 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    dataset:\n",
            "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
            "      manifest_filepath: /home/fkreuk/data/val_finetune.txt\n",
            "      min_duration: 3\n",
            "      n_segments: 66150\n",
            "    dataloader_params:\n",
            "      drop_last: false\n",
            "      shuffle: false\n",
            "      batch_size: 5\n",
            "      num_workers: 4\n",
            "    \n",
            "[NeMo W 2023-01-06 11:20:19 features:244] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-01-06 11:20:19 features:267] PADDING: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-01-06 11:20:19 features:244] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-01-06 11:20:19 features:267] PADDING: 0\n",
            "[NeMo I 2023-01-06 11:20:21 save_restore_connector:243] Model HifiGanModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--tts_hifigan/snapshots/3ba1fed954276287015654bf4c78060ffc9a4772/tts_hifigan.nemo.\n"
          ]
        }
      ],
      "source": [
        "# Load vocoder\n",
        "from nemo.collections.tts.models import HifiGanModel\n",
        "model = HifiGanModel.from_pretrained(model_name=\"nvidia/tts_hifigan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tpZ_NbRiXzE",
        "outputId": "545a0057-b2d4-49e0-f173-744b91b64f03"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-01-06 11:20:33 fastpitch:260] parse() is meant to be called in eval mode.\n",
            "[NeMo W 2023-01-06 11:20:33 fastpitch:325] generate_spectrogram() is meant to be called in eval mode.\n"
          ]
        }
      ],
      "source": [
        "import soundfile as sf\n",
        "parsed = spec_generator.parse(\"\"\"You don’t have to worry about retraining your model or how to publish the new model. \n",
        "Your model is updated on a regular basis. Furthermore, \n",
        "if you decide to retrain your model for whatever reason, it will not be an issue; \n",
        "you can just update the model on the cloud, and everyone will benefit.\"\"\")\n",
        "spectrogram = spec_generator.generate_spectrogram(tokens=parsed)\n",
        "audio = model.convert_spectrogram_to_audio(spec=spectrogram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ciSYTrfOiX5y"
      },
      "outputs": [],
      "source": [
        "# Save the audio to disk in a file called speech.wav\n",
        "sf.write(\"tts_en_fastpitch.wav\", audio.to('cpu').detach().numpy()[0], 22050) ##human alike"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVt-iMe3vuG1"
      },
      "source": [
        "TTS-EN-TACOTRON2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dWNUlpcfn2Og"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "import nemo\n",
        "from nemo.collections.tts.models.base import SpectrogramGenerator, Vocoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1bbthNappiF"
      },
      "outputs": [],
      "source": [
        "# Download and load the pretrained tacotron2 model\n",
        "spec_generator = SpectrogramGenerator.from_pretrained(\"tts_en_tacotron2\")\n",
        "\n",
        "# Download and load the pretrained waveglow model\n",
        "vocoder = Vocoder.from_pretrained(\"tts_waveglow_88m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty3Zt8BcpsYr",
        "outputId": "83f76956-ac45-4a65-e574-54d05fbadeb7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-01-06 11:23:42 tacotron2:145] parse() is meant to be called in eval mode.\n",
            "[NeMo W 2023-01-06 11:23:53 tacotron2:341] Reached max decoder steps 1000.\n",
            "[NeMo W 2023-01-06 11:25:59 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/torch/functional.py:632: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:801.)\n",
            "      return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "# All spectrogram generators start by parsing raw strings to a tokenized version of the string\n",
        "parsed = spec_generator.parse(\"\"\"You don’t have to worry about retraining your model or how to publish the new model. \n",
        "Your model is updated on a regular basis. Furthermore, \n",
        "if you decide to retrain your model for whatever reason, it will not be an issue; \n",
        "you can just update the model on the cloud, and everyone will benefit.\"\"\")\n",
        "# Then take the tokenized string and produce a spectrogram\n",
        "spectrogram = spec_generator.generate_spectrogram(tokens=parsed)\n",
        "# Finally, a vocoder converts the spectrogram to audio\n",
        "audio = vocoder.convert_spectrogram_to_audio(spec=spectrogram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hYtbJy-0pzfz"
      },
      "outputs": [],
      "source": [
        "# Save the audio to disk in a file called speech.wav\n",
        "sf.write(\"tts-waveglow-88m.wav\", audio.to('cpu').detach().numpy()[0], 22050)############very bad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRMS7d9txgFm"
      },
      "source": [
        "tts_en_fastspeech2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "ZlsBLTP6B-Cm",
        "outputId": "ff7848e2-24b1-4697-ab7c-ceaaa4fa4d7c"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-edddc8923847>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load FastSpeech 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastSpeech2Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mspec_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastSpeech2Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tts_en_fastspeech2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'FastSpeech2Model' from 'nemo.collections.tts.models' (/usr/local/lib/python3.8/dist-packages/nemo/collections/tts/models/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Load FastSpeech 2\n",
        "from nemo.collections.tts.models import FastSpeech2Model\n",
        "spec_generator = FastSpeech2Model.from_pretrained(\"tts_en_fastspeech2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jeTSpzMzwYI",
        "outputId": "1babb8e5-391e-457c-a543-aeae8d6feb1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-01-06 11:29:19 cloud:66] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_hifigan/versions/1.0.0rc1/files/tts_hifigan.nemo to /root/.cache/torch/NeMo/NeMo_1.14.0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo\n",
            "[NeMo I 2023-01-06 11:29:26 cloud:79] Download from cloud failed. Attempt 1 of 3\n",
            "[NeMo I 2023-01-06 11:29:36 common:912] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-01-06 11:29:40 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    dataset:\n",
            "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
            "      manifest_filepath: /home/fkreuk/data/train_finetune.txt\n",
            "      min_duration: 0.75\n",
            "      n_segments: 8192\n",
            "    dataloader_params:\n",
            "      drop_last: false\n",
            "      shuffle: true\n",
            "      batch_size: 64\n",
            "      num_workers: 4\n",
            "    \n",
            "[NeMo W 2023-01-06 11:29:40 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    dataset:\n",
            "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
            "      manifest_filepath: /home/fkreuk/data/val_finetune.txt\n",
            "      min_duration: 3\n",
            "      n_segments: 66150\n",
            "    dataloader_params:\n",
            "      drop_last: false\n",
            "      shuffle: false\n",
            "      batch_size: 5\n",
            "      num_workers: 4\n",
            "    \n",
            "[NeMo W 2023-01-06 11:29:40 features:244] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-01-06 11:29:40 features:267] PADDING: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-01-06 11:29:40 features:244] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-01-06 11:29:40 features:267] PADDING: 0\n",
            "[NeMo I 2023-01-06 11:29:42 save_restore_connector:243] Model HifiGanModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.14.0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load vocoder\n",
        "from nemo.collections.tts.models.base import Vocoder\n",
        "model = Vocoder.from_pretrained(model_name=\"tts_hifigan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ7gnwBizwnA"
      },
      "outputs": [],
      "source": [
        "# Generate audio\n",
        "import soundfile as sf\n",
        "parsed = spec_generator.parse(\"\"\"You don’t have to worry about retraining your model or how to publish the new model. \n",
        "Your model is updated on a regular basis. Furthermore, \n",
        "if you decide to retrain your model for whatever reason, it will not be an issue; \n",
        "you can just update the model on the cloud, and everyone will benefit.\"\"\")\n",
        "spectrogram = spec_generator.generate_spectrogram(tokens=parsed)\n",
        "audio = model.convert_spectrogram_to_audio(spec=spectrogram)\n",
        "\n",
        "# Save the audio to disk in a file called speech.wav\n",
        "sf.write(\"tts_en_fastspeech2.wav\", audio.to('cpu').detach().numpy()[0], 22050)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVKPvz5zq-AO"
      },
      "source": [
        "MIXER-TTS-X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d0772f38d5094873a07a64476ca57c60",
            "6c7410f0f00d452c8316a46211e8fb66",
            "5e8dfc225f394f6c85e53be6e83f23a3",
            "62535d5d554643fba639822c13e0f599",
            "dc80e779f3354201baaa59417253eb73",
            "bda9d8a33c824c7480ab73869e0e1609",
            "49b50f9feeec454281d48fa9c1258909",
            "9bd43cb3d1a840bab58b8e6e07543cd1",
            "8becb065181c47aa9d9a7b580d9f1df7",
            "81e07a45714b419a88c81c0fa40ccab7",
            "a8fd4238fad64c82acfdc0a37874799e",
            "6ecb5d6680b24e8e9028332f123e2e35",
            "995e6cc6afb84396870ac4dc2c065dab",
            "3752e7e5181143c182724c82c4d9ee51",
            "3a9341f83b3d4cfd9216be52f8bbc012",
            "b11ea1d2d49345a9aaff5861117ce33f",
            "9317811b92d54b258fb3292ba96f94de",
            "42e9332be8ae4cd5845c62721e69a7ed",
            "9f8e09502b554d1fb050909988688db1",
            "521f1e9f0f2f45b8b3d19f06e3128fa2",
            "5456f19f044b445885cb214a89a9a8e9",
            "9207fcb723c44e25b8cf551cd51f2892",
            "dfee0343b735488aa6222d11aa416150",
            "9cbe827d0f0b432994c223ebf675b252",
            "e806334d0e064697a3cf0f19d8b04fed",
            "58693fc6297d4d1dbd005bbe7faea36f",
            "db3bb8e6b7f2435ea8bd3388bd9ca609",
            "5879c90120e043e8ac4dd505e9fb6554",
            "a09e8e39c483499d8259bc654b9da9bb",
            "43795b6b943b493da13b3753578ed6a2",
            "ae91f32d613d4bb4b143bd26e6318eb4",
            "3d7fe5e9ad134a99b75d902d5fa8ad4b",
            "ef0e4ef27b9348a496e83c5ae99fafa1"
          ]
        },
        "id": "VcqG0efQxb9R",
        "outputId": "42e882bb-90c1-4372-fdcb-aa1801df5fd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-01-06 11:29:42 cloud:66] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_lj_mixerttsx/versions/1.6.0/files/tts_en_lj_mixerttsx.nemo to /root/.cache/torch/NeMo/NeMo_1.14.0/tts_en_lj_mixerttsx/3f77e9a4e457b181ac7f332517093fc0/tts_en_lj_mixerttsx.nemo\n",
            "[NeMo I 2023-01-06 11:29:47 common:912] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2023-01-06 11:29:50 tokenize_and_classify:87] Creating ClassifyFst grammars.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-01-06 11:30:28 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    dataset:\n",
            "      _target_: nemo.collections.tts.torch.data.MixerTTSDataset\n",
            "      manifest_filepath: lj_train.json\n",
            "      sample_rate: 22050\n",
            "      sup_data_path: sup_data_mixer_tts_dataset_align_prior_matrix_pitch_mixer_tts_231221\n",
            "      sup_data_types:\n",
            "      - align_prior_matrix\n",
            "      - pitch\n",
            "      - lm_tokens\n",
            "      n_fft: 1024\n",
            "      win_length: 1024\n",
            "      hop_length: 256\n",
            "      window: hann\n",
            "      n_mels: 80\n",
            "      lowfreq: 0\n",
            "      highfreq: 8000\n",
            "      max_duration: null\n",
            "      min_duration: 0.1\n",
            "      ignore_file: null\n",
            "      trim: false\n",
            "      pitch_fmin: 65.40639132514966\n",
            "      pitch_fmax: 2093.004522404789\n",
            "      lm_model: albert\n",
            "    dataloader_params:\n",
            "      drop_last: false\n",
            "      shuffle: true\n",
            "      batch_size: 32\n",
            "      num_workers: 4\n",
            "      pin_memory: false\n",
            "    \n",
            "[NeMo W 2023-01-06 11:30:28 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    dataset:\n",
            "      _target_: nemo.collections.tts.torch.data.MixerTTSDataset\n",
            "      manifest_filepath: lj_val.json\n",
            "      sample_rate: 22050\n",
            "      sup_data_path: sup_data_mixer_tts_dataset_align_prior_matrix_pitch_mixer_tts_231221\n",
            "      sup_data_types:\n",
            "      - align_prior_matrix\n",
            "      - pitch\n",
            "      - lm_tokens\n",
            "      n_fft: 1024\n",
            "      win_length: 1024\n",
            "      hop_length: 256\n",
            "      window: hann\n",
            "      n_mels: 80\n",
            "      lowfreq: 0\n",
            "      highfreq: 8000\n",
            "      max_duration: null\n",
            "      min_duration: 0.1\n",
            "      ignore_file: null\n",
            "      trim: false\n",
            "      pitch_fmin: 65.40639132514966\n",
            "      pitch_fmax: 2093.004522404789\n",
            "      lm_model: albert\n",
            "    dataloader_params:\n",
            "      drop_last: false\n",
            "      shuffle: false\n",
            "      batch_size: 32\n",
            "      num_workers: 2\n",
            "      pin_memory: false\n",
            "    \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0772f38d5094873a07a64476ca57c60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/742k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ecb5d6680b24e8e9028332f123e2e35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfee0343b735488aa6222d11aa416150",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/45.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.bias', 'predictions.decoder.bias', 'predictions.dense.weight']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-01-06 11:30:31 features:267] PADDING: 1\n",
            "[NeMo I 2023-01-06 11:30:31 save_restore_connector:243] Model MixerTTSModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.14.0/tts_en_lj_mixerttsx/3f77e9a4e457b181ac7f332517093fc0/tts_en_lj_mixerttsx.nemo.\n"
          ]
        }
      ],
      "source": [
        "# Load Mixer-TTS-X\n",
        "from nemo.collections.tts.models import MixerTTSModel\n",
        "spec_generator = MixerTTSModel.from_pretrained(\"tts_en_lj_mixerttsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-cp0wz41kOy",
        "outputId": "96f98010-dd32-44bc-ba99-a09388509eff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-01-06 11:30:31 cloud:66] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_lj_hifigan/versions/1.6.0/files/tts_en_lj_hifigan_ft_mixerttsx.nemo to /root/.cache/torch/NeMo/NeMo_1.14.0/tts_en_lj_hifigan_ft_mixerttsx/2286838f886ea3e82d0c3348b67e5035/tts_en_lj_hifigan_ft_mixerttsx.nemo\n",
            "[NeMo I 2023-01-06 11:30:44 common:912] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-01-06 11:30:50 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    dataset:\n",
            "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
            "      manifest_filepath: lj_train.json\n",
            "      min_duration: 0.75\n",
            "      n_segments: 8192\n",
            "    dataloader_params:\n",
            "      drop_last: false\n",
            "      shuffle: true\n",
            "      batch_size: 16\n",
            "      num_workers: 1\n",
            "    \n",
            "[NeMo W 2023-01-06 11:30:50 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    dataset:\n",
            "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
            "      manifest_filepath: lj_val.json\n",
            "      min_duration: 3\n",
            "      n_segments: 66048\n",
            "    dataloader_params:\n",
            "      drop_last: false\n",
            "      shuffle: false\n",
            "      batch_size: 16\n",
            "      num_workers: 1\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2023-01-06 11:30:50 features:267] PADDING: 0\n",
            "[NeMo I 2023-01-06 11:30:50 features:275] STFT using exact pad\n",
            "[NeMo I 2023-01-06 11:30:50 features:267] PADDING: 0\n",
            "[NeMo I 2023-01-06 11:30:50 features:275] STFT using exact pad\n",
            "[NeMo I 2023-01-06 11:30:51 save_restore_connector:243] Model HifiGanModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.14.0/tts_en_lj_hifigan_ft_mixerttsx/2286838f886ea3e82d0c3348b67e5035/tts_en_lj_hifigan_ft_mixerttsx.nemo.\n"
          ]
        }
      ],
      "source": [
        "# Load vocoder\n",
        "from nemo.collections.tts.models.base import SpectrogramGenerator, Vocoder\n",
        "model = Vocoder.from_pretrained(model_name=\"tts_en_lj_hifigan_ft_mixerttsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22WA3YibxcEB",
        "outputId": "90052fb3-9d15-4305-e362-4e3edbe3fc0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[NeMo W 2023-01-06 11:36:46 mixer_tts:658] parse() is meant to be called in eval mode.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Generate audio\n",
        "import soundfile as sf\n",
        "raw_text = \"\"\"You don’t have to worry about retraining your model or how to publish the new model. Your \n",
        "model is updated on a regular basis. Furthermore, if you decide to retrain your model for whatever reason, \n",
        "it will not be an issue; you can just update the model on the cloud, and everyone will benefit.\"\"\"\n",
        "parsed = spec_generator.parse(raw_text)\n",
        "spectrogram = spec_generator.generate_spectrogram(tokens=parsed, raw_texts=[raw_text])\n",
        "audio = model.convert_spectrogram_to_audio(spec=spectrogram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "FJxVXXquOIka",
        "outputId": "816d33c6-3ad5-441e-8a8a-b7583d8f79e0"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9995446592bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the audio to disk in a file called speech.wav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mixer-tts-en.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22050\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
          ]
        }
      ],
      "source": [
        "# Save the audio to disk in a file called speech.wav\n",
        "sf.write(\"mixer-tts-en.wav\", audio.to('cpu').numpy(), 22050)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX6oOoIYxEzX"
      },
      "source": [
        "GlowTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iege9ZQGx4AI"
      },
      "outputs": [],
      "source": [
        "# Load GlowTTS\n",
        "from nemo.collections.tts.models import GlowTTSModel\n",
        "spec_generator = GlowTTSModel.from_pretrained(\"tts_en_glowtts\")\n",
        "\n",
        "# Load vocoder\n",
        "from nemo.collections.tts.models import Vocoder\n",
        "model = Vocoder.from_pretrained(model_name=\"tts_hifigan\")\n",
        "\n",
        "# Generate audio\n",
        "import soundfile as sf\n",
        "parsed = spec_generator.parse(\"You can type your sentence here to get nemo to produce speech.\")\n",
        "spectrogram = spec_generator.generate_spectrogram(tokens=parsed)\n",
        "audio = model.convert_spectrogram_to_audio(spec=spectrogram)\n",
        "\n",
        "# Save the audio to disk in a file called speech.wav\n",
        "sf.write(\"speech.wav\", audio.to('cpu').numpy(), 22050)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z01C8gPfxJjB"
      },
      "source": [
        "tts_en_libritts_multispeaker_univnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVBeeF7dxC83"
      },
      "outputs": [],
      "source": [
        "# Load PastPitch\n",
        "from nemo.collections.tts.models import FastPitchModel\n",
        "spec_generator = FastPitchModel.from_pretrained(\"tts_en_fastpitch\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gp82drXfzFCH"
      },
      "outputs": [],
      "source": [
        "# Load UnivNet\n",
        "from nemo.collections.tts.models import Vocoder\n",
        "model = Vocoder.from_pretrained(model_name=\"tts_en_libritts_multispeaker_univnet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Dl0wzJex86k"
      },
      "outputs": [],
      "source": [
        "# Generate audio\n",
        "import soundfile as sf\n",
        "parsed = spec_generator.parse(\"\"\"Rationality means that an AI agent is assumed to take \n",
        "account of available information and uncertainty, potential costs \n",
        "and benefits, and to act consistently (logically) in choosing the best action\"\"\")\n",
        "spectrogram = spec_generator.generate_spectrogram(tokens=parsed)\n",
        "audio = model.convert_spectrogram_to_audio(spec=spectrogram)\n",
        "\n",
        "### Save the audio to disk in a file called speech.wav\n",
        "sf.write(\"tts_en_libritts_multispeaker_univnet.wav\", audio.to('cpu').detach().numpy()[0], 22050)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8L0WWMjx9cH"
      },
      "source": [
        "tts_en_e2e_fastspeech2hifigan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLMnN5YhGlMm"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "from nemo.collections.tts.models.\n",
        "\n",
        "# Load the model from NGC\n",
        "model = HifiGanModel.from_pretrained(model_name=\"tts_en_e2e_fastspeech2hifigan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liTRj1mYGoNQ"
      },
      "outputs": [],
      "source": [
        "# Run inference\n",
        "tokens = model.parse(\"Hey, I can speak!\")\n",
        "audio = model.convert_text_to_waveform(tokens=tokens)\n",
        "\n",
        "# Save the audio to disk in a file called speech.wav\n",
        "sf.write(\"speech.wav\", audio.to('cpu').numpy(), 22050)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUtTNO9XyBmW"
      },
      "source": [
        "tts_en_e2e_fastpitchhifigan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5tcToDyG5uo"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "from nemo.collections.tts.models import FastPitchHifiGanE2EModel\n",
        "\n",
        "# Load the model from NGC\n",
        "model = FastPitchHifiGanE2EModel.from_pretrained(model_name=\"tts_en_e2e_fastpitchhifigan\")\n",
        "\n",
        "# Run inference\n",
        "tokens = model.parse(\"Hey, I can speak!\")\n",
        "audio = model.convert_text_to_waveform(tokens=tokens)\n",
        "\n",
        "# Save the audio to disk in a file called speech.wav\n",
        "sf.write(\"tts_en_e2e_fastpitchhifigan.wav\", audio.to('cpu').numpy(), 22050)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8sU8pM5zOcZ"
      },
      "source": [
        "**VITS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Leq7fTa66Pgg",
        "outputId": "f446c618-3eda-46f0-86f3-c025e103f0e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting espnet\n",
            "  Downloading espnet-202211-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from espnet) (0.1.97)\n",
            "Requirement already satisfied: setuptools>=38.5.1 in /usr/local/lib/python3.8/dist-packages (from espnet) (59.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from espnet) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from espnet) (1.13.0+cu116)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from espnet) (3.8.2)\n",
            "Collecting protobuf<=3.20.1\n",
            "  Downloading protobuf-3.20.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata<5.0\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: librosa>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from espnet) (0.9.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.2 in /usr/local/lib/python3.8/dist-packages (from espnet) (5.4.1)\n",
            "Collecting pypinyin<=0.44.0\n",
            "  Downloading pypinyin-0.44.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kaldiio>=2.17.0 in /usr/local/lib/python3.8/dist-packages (from espnet) (2.17.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from espnet) (0.11.0)\n",
            "Collecting jamo==0.4.1\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Collecting pyworld>=0.2.10\n",
            "  Downloading pyworld-0.3.2.tar.gz (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-complex\n",
            "  Downloading torch_complex-0.4.3-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: nltk>=3.4.5 in /usr/local/lib/python3.8/dist-packages (from espnet) (3.7)\n",
            "Collecting humanfriendly\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting espnet-tts-frontend\n",
            "  Downloading espnet_tts_frontend-0.0.3-py3-none-any.whl (11 kB)\n",
            "Collecting fast-bss-eval==0.1.3\n",
            "  Downloading fast_bss_eval-0.1.3.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from espnet) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from espnet) (1.7.3)\n",
            "Collecting pytorch-wpe\n",
            "  Downloading pytorch_wpe-0.0.1-py3-none-any.whl (8.1 kB)\n",
            "Collecting ctc-segmentation>=1.6.6\n",
            "  Downloading ctc_segmentation-1.7.4.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ci-sdr\n",
            "  Downloading ci_sdr-0.0.2.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typeguard>=2.7.0 in /usr/local/lib/python3.8/dist-packages (from espnet) (2.7.1)\n",
            "Collecting configargparse>=1.2.1\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from espnet) (21.3)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from ctc-segmentation>=1.6.6->espnet) (0.29.32)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata<5.0->espnet) (3.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.8.0->espnet) (3.0.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.8.0->espnet) (1.6.0)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.8.0->espnet) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.8.0->espnet) (0.56.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.8.0->espnet) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.8.0->espnet) (0.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.8.0->espnet) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>=3.4.5->espnet) (8.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk>=3.4.5->espnet) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk>=3.4.5->espnet) (2022.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->espnet) (3.0.9)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->espnet) (1.15.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->espnet) (4.4.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.8/dist-packages (from ci-sdr->espnet) (0.6.0)\n",
            "Collecting jaconv\n",
            "  Downloading jaconv-0.3.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: g2p-en in /usr/local/lib/python3.8/dist-packages (from espnet-tts-frontend->espnet) (2.1.0)\n",
            "Requirement already satisfied: inflect>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from espnet-tts-frontend->espnet) (2.1.0)\n",
            "Collecting unidecode>=1.0.22\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->espnet) (2.21)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.45.1->librosa>=0.8.0->espnet) (0.39.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa>=0.8.0->espnet) (2.25.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa>=0.8.0->espnet) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.1->librosa>=0.8.0->espnet) (3.1.0)\n",
            "Requirement already satisfied: distance>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from g2p-en->espnet-tts-frontend->espnet) (0.1.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->espnet) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->espnet) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->espnet) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->espnet) (1.26.13)\n",
            "Building wheels for collected packages: fast-bss-eval, ctc-segmentation, pyworld, ci-sdr, jaconv\n",
            "  Building wheel for fast-bss-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fast-bss-eval: filename=fast_bss_eval-0.1.3-py3-none-any.whl size=44261 sha256=c882ff8ff074ece98c692d680fa6501d9f6b392e6494d5d0cdd7732204e1e559\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/6b/47/b6c63872ec8ac7f73a147c79ff33296a5e61125565ade0e51a\n",
            "  Building wheel for ctc-segmentation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ctc-segmentation: filename=ctc_segmentation-1.7.4-cp38-cp38-linux_x86_64.whl size=126563 sha256=d3b30c60cbf70d333c024354b51f8f901777823b2baf50b628672a46b33d1d1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/1c/94/ca772c6c094ec3096a5cd5fca44ab7b688f1ea7a7588bb1d1b\n",
            "  Building wheel for pyworld (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.3.2-cp38-cp38-linux_x86_64.whl size=673639 sha256=f7beba2c89c91f4d198fa33a99a783b26ca180c2feac7d22e080f393fae1c32d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/b1/d2/8c78d691f7d5b0bb4ba9993926db209429c92686476837627f\n",
            "  Building wheel for ci-sdr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ci-sdr: filename=ci_sdr-0.0.2-py3-none-any.whl size=15276 sha256=654becf2b4e2c379829e17aca707a801b52f72103b4c23311c6203abf8ad9598\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/81/27/e3c60b66b70e72d567ffa69009f09d936c9f49852aa0923d5f\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.3.3-py3-none-any.whl size=16149 sha256=4b2e4ca4583e4341d657a8f69f8dfb687d4174851830fa2a9f83faeb5914f4fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/35/01/44a4e0440636d2d56517751e30be96256c7c87e75dbbcc6dcf\n",
            "Successfully built fast-bss-eval ctc-segmentation pyworld ci-sdr jaconv\n",
            "Installing collected packages: jamo, jaconv, unidecode, torch-complex, pyworld, pytorch-wpe, pypinyin, protobuf, importlib-metadata, humanfriendly, ctc-segmentation, configargparse, fast-bss-eval, ci-sdr, espnet-tts-frontend, espnet\n",
            "  Attempting uninstall: pypinyin\n",
            "    Found existing installation: pypinyin 0.47.1\n",
            "    Uninstalling pypinyin-0.47.1:\n",
            "      Successfully uninstalled pypinyin-0.47.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 5.2.0\n",
            "    Uninstalling importlib-metadata-5.2.0:\n",
            "      Successfully uninstalled importlib-metadata-5.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.11.0 which is incompatible.\n",
            "onnx 1.13.0 requires protobuf<4,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "googleapis-common-protos 1.57.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-firestore 2.7.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-datastore 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery 3.4.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.17.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ci-sdr-0.0.2 configargparse-1.5.3 ctc-segmentation-1.7.4 espnet-202211 espnet-tts-frontend-0.0.3 fast-bss-eval-0.1.3 humanfriendly-10.0 importlib-metadata-4.13.0 jaconv-0.3.3 jamo-0.4.1 protobuf-3.20.1 pypinyin-0.44.0 pytorch-wpe-0.0.1 pyworld-0.3.2 torch-complex-0.4.3 unidecode-1.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install espnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "QhUzONP8jBar",
        "outputId": "1f252f8f-ede9-43b4-a087-94357c6ecde7"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c010b4c8fa66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mespnet2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts_inference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mText2Speech\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mText2Speech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"espnet/kan-bayashi_ljspeech_vits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m speech, *_ = model(\"\"\"You don’t have to worry about retraining your model or how to publish the new model.\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'espnet2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from espnet2.bin.tts_inference import Text2Speech\n",
        "\n",
        "model = Text2Speech.from_pretrained(\"espnet/kan-bayashi_ljspeech_vits\")\n",
        "\n",
        "speech, *_ = model(\"\"\"You don’t have to worry about retraining your model or how to publish the new model.\n",
        "Your model is updated on a regular basis. Furthermore, if you decide to retrain your model for whatever reason,\n",
        " it will not be an issue; you can just update the model on the cloud, and everyone will benefit.\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUaKIgLPiuZM"
      },
      "source": [
        "Refer below links:\n",
        "https://catalog.ngc.nvidia.com/orgs/nvidia/collections/nemo_tts\n",
        "https://youtu.be/1Bmg1c5U5Bg\n",
        "https://catalog.ngc.nvidia.com/orgs/nvidia/resources/flowtron/quick-start-guide\n",
        "https://paperswithcode.com/sota/text-to-speech-synthesis-on-ljspeech\n",
        "https://catalog.ngc.nvidia.com/orgs/nvidia/teams/adlr/models/flowtron\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1614edd509a74de7aa1e341630d11e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b06cc5610e14636b4278f61a7c323b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8c03d5f1c5b4dd28643c2113fd6b554",
            "placeholder": "​",
            "style": "IPY_MODEL_e85fafcbca58451b92e9b44aa31b5947",
            "value": " 315M/315M [00:08&lt;00:00, 16.4MB/s]"
          }
        },
        "3752e7e5181143c182724c82c4d9ee51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f8e09502b554d1fb050909988688db1",
            "max": 684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_521f1e9f0f2f45b8b3d19f06e3128fa2",
            "value": 684
          }
        },
        "37973b413f5744308fdf2db22b9bc91a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a9341f83b3d4cfd9216be52f8bbc012": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5456f19f044b445885cb214a89a9a8e9",
            "placeholder": "​",
            "style": "IPY_MODEL_9207fcb723c44e25b8cf551cd51f2892",
            "value": " 684/684 [00:00&lt;00:00, 17.1kB/s]"
          }
        },
        "3d7fe5e9ad134a99b75d902d5fa8ad4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e9332be8ae4cd5845c62721e69a7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43795b6b943b493da13b3753578ed6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4786e17e28ef40e99e7bd1f689cc3db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bddd5b7a7d34d5cae8e01fc70ec3153",
            "placeholder": "​",
            "style": "IPY_MODEL_1614edd509a74de7aa1e341630d11e67",
            "value": "Downloading: 100%"
          }
        },
        "49b50f9feeec454281d48fa9c1258909": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "521f1e9f0f2f45b8b3d19f06e3128fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5456f19f044b445885cb214a89a9a8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58693fc6297d4d1dbd005bbe7faea36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d7fe5e9ad134a99b75d902d5fa8ad4b",
            "placeholder": "​",
            "style": "IPY_MODEL_ef0e4ef27b9348a496e83c5ae99fafa1",
            "value": " 45.2M/45.2M [00:00&lt;00:00, 52.7MB/s]"
          }
        },
        "5879c90120e043e8ac4dd505e9fb6554": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e8dfc225f394f6c85e53be6e83f23a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bd43cb3d1a840bab58b8e6e07543cd1",
            "max": 760289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8becb065181c47aa9d9a7b580d9f1df7",
            "value": 760289
          }
        },
        "62535d5d554643fba639822c13e0f599": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81e07a45714b419a88c81c0fa40ccab7",
            "placeholder": "​",
            "style": "IPY_MODEL_a8fd4238fad64c82acfdc0a37874799e",
            "value": " 742k/742k [00:00&lt;00:00, 3.47MB/s]"
          }
        },
        "6c7410f0f00d452c8316a46211e8fb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bda9d8a33c824c7480ab73869e0e1609",
            "placeholder": "​",
            "style": "IPY_MODEL_49b50f9feeec454281d48fa9c1258909",
            "value": "Downloading spiece.model: 100%"
          }
        },
        "6ecb5d6680b24e8e9028332f123e2e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_995e6cc6afb84396870ac4dc2c065dab",
              "IPY_MODEL_3752e7e5181143c182724c82c4d9ee51",
              "IPY_MODEL_3a9341f83b3d4cfd9216be52f8bbc012"
            ],
            "layout": "IPY_MODEL_b11ea1d2d49345a9aaff5861117ce33f"
          }
        },
        "81e07a45714b419a88c81c0fa40ccab7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a0d1a5a30194ecb95ed105335aa7794": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a504b90dc96486bb99017cb1647a0cc",
            "max": 315386678,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c824928fdfae45d7a6cc901fd377f758",
            "value": 315386678
          }
        },
        "8becb065181c47aa9d9a7b580d9f1df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9207fcb723c44e25b8cf551cd51f2892": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9317811b92d54b258fb3292ba96f94de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "995e6cc6afb84396870ac4dc2c065dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9317811b92d54b258fb3292ba96f94de",
            "placeholder": "​",
            "style": "IPY_MODEL_42e9332be8ae4cd5845c62721e69a7ed",
            "value": "Downloading config.json: 100%"
          }
        },
        "9a504b90dc96486bb99017cb1647a0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bd43cb3d1a840bab58b8e6e07543cd1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bddd5b7a7d34d5cae8e01fc70ec3153": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cbe827d0f0b432994c223ebf675b252": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5879c90120e043e8ac4dd505e9fb6554",
            "placeholder": "​",
            "style": "IPY_MODEL_a09e8e39c483499d8259bc654b9da9bb",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "9f8e09502b554d1fb050909988688db1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a09e8e39c483499d8259bc654b9da9bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8fd4238fad64c82acfdc0a37874799e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae91f32d613d4bb4b143bd26e6318eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b11ea1d2d49345a9aaff5861117ce33f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda9d8a33c824c7480ab73869e0e1609": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c824928fdfae45d7a6cc901fd377f758": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0772f38d5094873a07a64476ca57c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c7410f0f00d452c8316a46211e8fb66",
              "IPY_MODEL_5e8dfc225f394f6c85e53be6e83f23a3",
              "IPY_MODEL_62535d5d554643fba639822c13e0f599"
            ],
            "layout": "IPY_MODEL_dc80e779f3354201baaa59417253eb73"
          }
        },
        "d563b11073de4ddca69af5041317b5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4786e17e28ef40e99e7bd1f689cc3db2",
              "IPY_MODEL_8a0d1a5a30194ecb95ed105335aa7794",
              "IPY_MODEL_1b06cc5610e14636b4278f61a7c323b1"
            ],
            "layout": "IPY_MODEL_37973b413f5744308fdf2db22b9bc91a"
          }
        },
        "d8c03d5f1c5b4dd28643c2113fd6b554": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db3bb8e6b7f2435ea8bd3388bd9ca609": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc80e779f3354201baaa59417253eb73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfee0343b735488aa6222d11aa416150": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cbe827d0f0b432994c223ebf675b252",
              "IPY_MODEL_e806334d0e064697a3cf0f19d8b04fed",
              "IPY_MODEL_58693fc6297d4d1dbd005bbe7faea36f"
            ],
            "layout": "IPY_MODEL_db3bb8e6b7f2435ea8bd3388bd9ca609"
          }
        },
        "e806334d0e064697a3cf0f19d8b04fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43795b6b943b493da13b3753578ed6a2",
            "max": 47376696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae91f32d613d4bb4b143bd26e6318eb4",
            "value": 47376696
          }
        },
        "e85fafcbca58451b92e9b44aa31b5947": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef0e4ef27b9348a496e83c5ae99fafa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
